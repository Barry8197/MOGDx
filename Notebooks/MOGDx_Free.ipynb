{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a063509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Library Import \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys  \n",
    "sys.path.insert(0, './../MAIN/')\n",
    "from utils import *\n",
    "from GNN_MME import *\n",
    "from train import *\n",
    "import preprocess_functions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold , train_test_split\n",
    "import networkx as nx\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Finished Library Import \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b353b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = './../../data/TCGA/BRCA/raw/'\n",
    "snf_net = 'RPPA_mRNA_graph.graphml'\n",
    "index_col = 'index'\n",
    "target = 'paper_BRCA_Subtype_PAM50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b0dba-3496-432e-9936-baa622682d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')# Get GPU device name, else use CPU\n",
    "print(\"Using %s device\" % device)\n",
    "get_gpu_memory()\n",
    "\n",
    "datModalities , meta = data_parsing(data_input , ['RPPA', 'mRNA'] , target , index_col)\n",
    "\n",
    "graph_file = data_input + '../Networks/' + snf_net\n",
    "g = nx.read_graphml(graph_file)\n",
    "\n",
    "meta = meta.loc[sorted(meta.index)]\n",
    "label = F.one_hot(torch.Tensor(list(meta.astype('category').cat.codes)).to(torch.int64))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "\n",
    "print(skf)\n",
    "\n",
    "MME_input_shapes = [datModalities[mod].shape[1] for mod in datModalities]\n",
    "\n",
    "h = reduce(merge_dfs , list(datModalities.values()))\n",
    "h = h.loc[sorted(h.index)]\n",
    "\n",
    "del datModalities\n",
    "gc.collect()\n",
    "\n",
    "output_metrics = []\n",
    "test_logits = []\n",
    "test_labels = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(meta.index, meta)) :\n",
    "    \n",
    "    model = GCN_MME(MME_input_shapes , [16 , 16] , 64 , [32]  , len(meta.unique())).to(device)\n",
    "    g = dgl.graph(([], []) , num_nodes=len(meta))\n",
    "    g = dgl.add_self_loop(g)\n",
    "    g.ndata['feat'] = torch.Tensor(h.to_numpy())\n",
    "    g.ndata['label'] = label\n",
    "    g = g.to(device)\n",
    "    \n",
    "    print(model)\n",
    "    print(g)\n",
    "\n",
    "    G = train(g, train_index, device ,  model , meta , 500 , 1e-3 , 20, pretrain=True)\n",
    "    \n",
    "    sampler = NeighborSampler(\n",
    "        [15 for i in range(len(model.gnnlayers))],  # fanout for each layer\n",
    "        prefetch_node_feats=['feat'],\n",
    "        prefetch_labels=['label'],\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        g,\n",
    "        torch.Tensor(test_index).to(torch.int64).to(device),\n",
    "        sampler,\n",
    "        device=device,\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "        use_uva=False,\n",
    "    )\n",
    "    \n",
    "    test_output_metrics = evaluate(model , g, test_dataloader)\n",
    "    \n",
    "    print(\n",
    "        \"Pretraining | Loss = {:.4f} | Accuracy = {:.4f} \".format(\n",
    "         test_output_metrics[0] , test_output_metrics[1] )\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    model = model.apply(init_weights)\n",
    "\n",
    "    g = dgl.from_networkx(G , node_attrs=['idx' , 'label'])\n",
    "    g.ndata['feat'] = torch.Tensor(h.to_numpy())\n",
    "    g.ndata['label'] = label\n",
    "    g = g.to(device)\n",
    "    \n",
    "    print(g)\n",
    "    \n",
    "    loss_plot = train(g, train_index, device ,  model , meta , 2000 , 1e-3 , 100)\n",
    "    \n",
    "    sampler = NeighborSampler(\n",
    "        [15 for i in range(len(model.gnnlayers))],  # fanout for each layer\n",
    "        prefetch_node_feats=['feat'],\n",
    "        prefetch_labels=['label'],\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        g,\n",
    "        torch.Tensor(test_index).to(torch.int64).to(device),\n",
    "        sampler,\n",
    "        device=device,\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "        use_uva=False,\n",
    "    )\n",
    "    \n",
    "    test_output_metrics = evaluate(model , g, test_dataloader)\n",
    "\n",
    "    print(\n",
    "        \"Fold : {:01d} | Test Accuracy = {:.4f} | F1 = {:.4f} \".format(\n",
    "        i+1 , test_output_metrics[1] , test_output_metrics[2] )\n",
    "    )\n",
    "    \n",
    "    test_logits.extend(test_output_metrics[-2])\n",
    "    test_labels.extend(test_output_metrics[-1])\n",
    "    \n",
    "    output_metrics.append(test_output_metrics)\n",
    "    if i == 0 : \n",
    "        best_model = model\n",
    "        best_idx = i\n",
    "    elif output_metrics[best_idx][1] < test_output_metrics[1] : \n",
    "        best_model = model\n",
    "        best_idx   = i\n",
    "\n",
    "    get_gpu_memory()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Clearing gpu memory')\n",
    "    get_gpu_memory()\n",
    "\n",
    "test_logits = torch.stack(test_logits)\n",
    "test_labels = torch.stack(test_labels)\n",
    "\n",
    "accuracy = []\n",
    "F1 = []\n",
    "i = 0\n",
    "for metric in output_metrics :\n",
    "    \n",
    "    accuracy.append(metric[1])\n",
    "    F1.append(metric[2])\n",
    "\n",
    "\n",
    "print(\"%i Fold Cross Validation Accuracy = %2.2f \\u00B1 %2.2f\" %(5 , np.mean(accuracy)*100 , np.std(accuracy)*100))\n",
    "print(\"%i Fold Cross Validation F1 = %2.2f \\u00B1 %2.2f\" %(5 , np.mean(F1)*100 , np.std(F1)*100))\n",
    "\n",
    "confusion_matrix(test_logits , test_labels , meta.astype('category').cat.categories)\n",
    "plt.title('Test Accuracy = %2.1f %%' % (np.mean(accuracy)*100))\n",
    "\n",
    "precision_recall_plot , all_predictions_conf = AUROC(test_logits, test_labels , meta)\n",
    "\n",
    "node_predictions = []\n",
    "node_true        = []\n",
    "display_label = meta.astype('category').cat.categories\n",
    "for pred , true in zip(all_predictions_conf.argmax(1) , list(test_labels.detach().cpu().argmax(1).numpy()))  : \n",
    "    node_predictions.append(display_label[pred])\n",
    "    node_true.append(display_label[true])\n",
    "\n",
    "tst = pd.DataFrame({'Actual' : node_true , 'Predicted' : node_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bc089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
